\chapter{Conclusions and Future Directions} \label{chap:chap-6}


\section{Conclusions}
Measurement studies demonstrate that traffic exhibits burstiness across a wide range of timescales in diverse contexts, including local networks, WANs, data centers, and WWW traffic. Of particular interest are microsecond-scale congestion events, commonly referred to as \emph{microbursts}, which have been the subject of numerous measurement and control studies. However, the role of host networking in shaping burstiness at various timescales remains relatively under-explored. This dissertation starts by addressing this gap through investigating what causes traffic to emerge from hosts in bursts.
In Chapter \S\ref{chap:chapter-2} we examined whether burstiness is a \emph{scale-invariant} property of network traffic, persisting across multiple levels of granularity.
We introduced \textit{Valinor}, a high-resolution traffic measurement framework designed to analyze the impact of host networking on traffic burstiness across different timescales. \textit{Valinor} consists of two components: an in-host timestamping framework (\textit{Valinor-H}) that captures packet metadata near the final stages of software processing using \textit{eBPF}, and an in-network packet timestamping framework (\textit{Valinor-N}) that records packet arrival timestamps in a programmable switch. This dual approach provides network operators with deep visibility into how different host networking elements create or influence bursty traffic patterns.

Our analysis using \textit{Valinor} confirms that classical models of burstiness, which attribute burstiness primarily to application-layer characteristics, oversimplify the phenomenon. Instead, we found that host configurations—including hardware, transport protocols, and scheduling mechanisms—significantly influence burstiness at multiple timescales. For example, newer transport protocols, such as Homa, DCTCP, and BBR, demonstrate varying burstiness patterns, with BBR exhibiting reduced burstiness even at coarse timescales. This suggests that long-standing assumptions underlying techniques like topology engineering and multi-timescale congestion control may not hold under modern traffic patterns.

Furthermore, we quantified the effects of TCP pacing, packet scheduling, and active queue management techniques, such as CoDel, in mitigating bursts. Our results indicate that lower-layer functions—such as TCP segmentation offloading (TSO) and NIC scheduling—can override the intended effects of these mechanisms, often amplifying burstiness instead. This underscores the need to shift burst control mechanisms further down the packet processing pipeline. Given the variability of burstiness due to evolving hardware, transport protocols, and workloads, our findings highlight the importance of continuous traffic measurement.

Next, in Chapter \S\ref{chap:chap-3}, we examined the limitations of Deficit Round-Robin (DRR) scheduling in modern Internet traffic environments and introduced \textit{Self-Clocked Round-Robin} (\textit{SCRR}). We showed that while DRR has been widely adopted due to its scalability, it struggles with high scheduling delays for short bursty flows. Additionally, we showed that DRR is sensitive to quantum size configuration and there is no correct answer in finding its right quantum. These issues are exacerbated by the diverse traffic patterns of modern workloads, such as video conferencing, streaming, and gaming, which feature irregular packet sizes and bursty transmission patterns. Our analysis suggests that DRR's inability to efficiently handle bursty, latency-sensitive flows leads to significantly increased application latency, even on high-speed networks.

To address these challenges, we introduced \textit{SCRR}, a novel multi-queue round-robin scheduler that integrates virtual clocking principles from Fair Queuing to eliminate quantum size dependency while maintaining DRR’s efficiency and scalability. \textit{SCRR} adapts dynamically to bursty traffic and packet size variations without requiring explicit flow information. We introduced enhancements that prioritize bursty flows while preserving fairness, allowing short, latency-sensitive flows to progress quickly without disrupting overall scheduling fairness. Our theoretical analysis confirms that \textit{SCRR} maintains the fairness guarantees of DRR while significantly reducing burst-related delays.
We evaluated \textit{SCRR} using both theoretical analysis and testbed experiments. With its lightweight design, adaptability to traffic variations, and ease of deployment, \textit{SCRR} presents a promising step toward replacing existing packet schedulers in both software and hardware implementations. Its ability to balance fairness, low latency, and scalability makes it an ideal candidate for modern multi-party wide-area networks.

In Chapter \S\ref{chap:chap-4}, we turned our attention to the formation of microsecond-scale bursts at the core of the network. Recent studies indicate that bursts, particularly in large-scale datacenters, can be triggered by incast traffic patterns, where many hosts transmit data to a single receiver. Techniques like load balancing and traffic engineering in the network core attempt to manage bursts but can fail under high load and large-scale incasts, where buffer capacity and path distribution are insufficient. Similarly, host-centric techniques that rely on congestion feedback or application-level adjustments often react too slowly to effectively prevent burst formation.

In response to these challenges, we proposed \textit{Vertigo}, a comprehensive forwarding solution that leverages both edge/host knowledge and network core capabilities to manage bursts. The network core must handle bursts in real-time, distinguishing between transient bursts and persistent congestion. \textit{Vertigo} achieves this by tagging packets with flow size information at the sender and using this information in the network core to selectively deflect or drop packets based on their likely contribution to congestion. Additionally, \textit{Vertigo} includes a receiver-side re-sequencing layer to handle the reordering caused by deflection, ensuring the proper packet order for transport and application protocols.

Through extensive simulations, \textit{Vertigo} demonstrates superior performance compared to existing network-centric techniques such as DIBS, DRILL, and ECMP. It significantly reduces mean incast query completion times, even under high utilization and bursty workloads. 

This study advocates for periodic burst measurement and re-thinking the design of networks. In Chapter \S\ref{chap:related-work}, we summarize the literature on bursts, packet scheduling, and and traffic management in datacenters. In what comes next, we explore the future work on realizing burst-tolerant networks.



\section{Future Directions}

\subsection{Long-term Directions}
Workloads and networking technologies are constantly evolving. In the recent years, AI workloads have become dominant in data centers \cite{hyperscale,meta}. Streaming workloads and video conferencing have become popular in Internet \cite{pandemic,video,zoom,confucius,gaming}. To keep up with such demand, networking technologies are also improving. Datacenter networks commonly use 400-800 Gbps connections \cite{llm,meta}, GPU-to-GPU communication is becoming an important consideration for networks that host AI, and multi-gigabit home Internet is becoming common \cite{comcast}.

\textbf{The need for periodic measurements.}
As workloads evolve, the burstiness characteristics of traffic constantly change. Hence, the established load-balancing, traffic engineering, congestion control, and scheduling paradigms will need to be updated and improved.
Improving the accuracy and efficiency of traffic measurement frameworks, such as the one introduced in this thesis, will streamline transitions to new network designs while allowing the network operators to have a realtime view of traffic characteristics in their networks.
\\
\textbf{Revisiting old assumptions about network traffic.}
Our exploration of fair packet scheduling decisively underscored that \emph{the traffic characteristics change over time, and with that, the design of network must change!} Many of the existing technologies that we use in our networks are decades old. For example, the congestion control, and rate-limiting for the Internet still heavily rely on packet loss as congestion signal and enforcement mechanism, respectively. With the increase in link capacities, Bandwidth-Delay Product (BDP) raises and can cause significant bufferbloat \cite{bufferbloat} and burstiness. More work is required to quantify the contribution of such systems on burstiness and ultimately designing modern alternatives.

\subsection{Short-term Directions}

\textbf{More Scalable Traffic Measurement.}
\textit{Valinor} proved to be a useful asset in studying the impact of host networking on traffic characteristics. However, similar to some of the recent related work \cite{milisampler,incast}, we assumed that \textit{Valinor}'s data can be collected during short periods (seconds up to minutes), for a subset of traffic, and processed offline. \textit{Valinor} produces a substantial amount of data, even when capturing the traffic for a few seconds, therefore enabling it on all switch ports or on faster networks poses a scalability challenge. Future deployments might also require online burst measurements. More work is required to overcome the scalability challenges of measurement systems at high-speed networks.

\textbf{Pushing the traffic shaping down the network stack.} Our study in \cite{valinor} proved that the existing traffic shaping (e.g., pacing and scheduling) implemented in software are compromised by the offloading functions of exciting NICs. In fact, commodity NICs are very limited in traffic management and scheduling functionalities that they expose to their users. The rise of open-source NIC designs  \cite{corundum} can be a great start to this end.

\textbf{Policy-rich fair packet scheduling.}
\textit{SCRR} was a step toward achieving lower latency while maintaining fairness. However, more complex deployments may require support for seamless switching between scheduling policies. We believe that self-clocking is a great tool for exploring such ideas in the future.

\textbf{Practicality of selective packet deflection.}
The ability to separate short-term bursts from lasting congestion caused \textit{Vertigo} to significantly outperform other in-network reactive measures to congestion and burstiness. While the approximation of selective  deflection has been shown to be implementable \cite{practical-deflection}, further work is required to identify and address the roadblocks in realizing SRPT scheduling and selective packet deflection in datacenter networks.

\textbf{Interaction of deflection with congestion control.}
Deflection prevents packet loss by deflecting excess packets to neighboring buffers. However, that also means that the packet loss signal which is used to rectify the transmission rate will never reach the sender host. A future research study can investigate how we can replace the packet loss signal to prevent the network from over-congestion.